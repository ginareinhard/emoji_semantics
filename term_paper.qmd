---
title: "Term paper"
subtitle: ""
author: "Rose Hörsting & Gina Reinhard"
date: "2024-09-15"
engine: knitr
bibliography: references.bib
format: 
  html:
    toc: true
    toc-depth: 3
    fig-width: 10
    fig-height: 8
    number-sections: true
    embed-resources: true
link-citations: true
csl: "apa_7th.csl"
---

```{r ragg, include=FALSE}

#install.packages("ragg")
library(ragg)

```

```{r setup, include=FALSE}

knitr::opts_chunk$set(dev = "ragg_png", warning = FALSE, message = FALSE)

```

```{r include=FALSE}

library(checkdown)

```

#### **Chapter overview** {.unnumbered}

In this chapter, we...

## Session set up

```{r load-libraries, message=FALSE}

library(here)
library(tidyverse)
#install.packages("ggpubr")
library(ggpubr)
#install.packages("scales")
library(scales)
#install.packages(patchwork)
library(patchwork)

```

## Introducing the study

<!-- Kapitel überarbeitet -->

<!--Everyday, millions of people use emojis in their text messages as a means to communicate their emotions. --> 
Face emojis stand in for facial expressions and thereby fundamentally contribute to the subtext of a text message. Several studies have investigated the relationship between emojis and the emotions they depict. However, as emojis are a relatively recently occuring phenomenon, there is still a lot to be discovered. In this chapter, we will look into this study by @fricke2024semantic:

<!-- Ich finde die Einleitung für eine Hausarbeit sehr gut, mein erster Eindruck war nur ggf. für unseren Zweck zu weit ausgeholt? -->

> Fricke, L., Grosz, P. G., & Scheffler, T. (2024). Semantic differences in visually similar face emojis. Language and Cognition, 1–15. <https://doi.org/10.1017/langcog.2024.12>

They compare visually similar emojis using a face emoji annotation system developed by @fugate2021implications. This annotation system is based on the Facial Action Coding System (FACS) for human faces invented by @ekman1978facial. @fricke2024semantic assign numbers to features such as *eyebrows arched* and *eyes wide*. These numbers are called Action Units, short AUs. As you can see in @fig-emojipairs, each emoji consists of several AUs:

![Emoji pairs and their contexts, @fricke2024semantic](images/emoji_pairs.png){#fig-emojipairs fig-align="center" width="700"}

@fricke2024semantic distinguish two different types of emoji pairs: In the \[AU+\] condition, the visual difference between emojis corresponds to a difference between AUs. In the \[AU-\] condition, the visual difference does not correspond to an AU difference. 

Their central research question is: **Do AU-differences lead to differences in meaning between the two emojis of a pair?**

@fricke2024semantic compare two approaches that answer this question differently: The pictorial approach by @maier2023emojis considers emojis to be depictions of the writer´s face in the moment of typing. In contrast, the lexicalist approach grosz2023semantics emphasises the meanings of emojis as described by words.

Following the pictorial approach, @fricke2024semantic predict that small visual differences between emojis that do not correspond to human facial features (AU-) are less semantically relevant than differences corresponding to human facial features (AU+)

<!-- Beispiele gelöscht -->

::: {.callout-note title="How did the experiment work?"}
### Design {.unnumbered}

Three \[AU+\] and three \[AU-\] emoji pairs were created, as depicted in @fig-emojipairs. Each pair was assigned two contexts (for example *happiness* and *(cheeky) laughter*), where each context corresponded to a prominent usage or meaning of one emoji but not the other. The contexts were assigned based both on <https://emojipedia.org> and on a previous norming study by the authors. Four one-sentence-stories (lexicalisations) were created for each context, which yielded 48 testing items. <!-- These testing items were divided up into into four lists. Each list also contained 12 filler items, so that each participant saw 24 items.-->

### Procedure {.unnumbered}

As you can see in @fig-testitems, situations that illustrated the contexts were presented to participants, and participants were asked to help a male ("Alex") or female ("Anna") friend choosing the fitting emoji. Each participant saw each emoji pair twice (in one context favoring member A and in another context favoring member B). The rate with which the context-matching emoji was chosen was measured (Dependent variable). After the experiment, the participants were asked questions regarding their emoji use frequency, attitude towards emojis, understanding of emojis, WhatsApp use and their smartphone operating system.

![Example of a test item in @fricke2024semantic´s experiment](images/test_items.png){#fig-testitems fig-align="center" width="500"} 

The lexicalist approach predicts that it does not matter whether visual (AU) differences correspond to facial characteristics or not: For both types of pairs, the context-matching emoji should be chosen more often than the non-matching one. <!-- erstmal hierhin verschoben, weil von den Kontexten vor der blauen Box noch nicht die Rede war -->

In contrast, @fricke2024semantic expect that participants will choose the context-matching emoji more often in the \[AU+\] condition than in the \[AU-\] condition. For the \[AU-\] pairs, the pattern is predicted to be more random. <!-- erstmal hierhin verschoben, weil von den Kontexten vorher noch nicht die Rede war -->
:::

## Data wrangling

Import the data using "here":

```{r import-data, message=FALSE}

raw_data <- read.csv(file = here("data", "raw_data.csv"))

```

Filter out participants who exceed the maximum age of 35 years specified by @fricke2024semantic (p. 8): (refer to <https://elenlefoll.github.io/RstatsTextbook/7_VariablesFunctions.html> **7.5.2 Piped Functions**).

```{r clean-data}

data <- raw_data |> 
  filter(age <= 35)

```

## Exploring the relationship between gender and emoji understanding

@fricke2024semantic also asked participants about their gender, their attitude towards emojis, how often they use emojis on WhatsApp and how well they think they understand emojis. They visualised the distribution of male and female gender for emoji use and emoji attitude:

![Image from @fricke2024semantic](images/emoji_use.png){#fig-emojiuse fig-align="center" width="500"}

![Image from @fricke2024semantic](images/emoji_attitude.png){#fig-emojiattitude fig-align="center" width="500"}

Women seem to use emojis more often and have a more positive attitude towards emojis than men. We want to find out whether women also reported a higher level of emoji understanding than men.

Doing this will take 3 steps:

1.  Calculating the absolute frequencies of the genders in the data
2.  Calculating the relative frequencies of the different levels of emoji understanding for each gender
3.  Creating a barplot for emoji understanding similar to the plots above

(descriptive statistics?)

### Gender frequencies

Let's first get a general overview: How many men, women, and non-binary people participated in the study?

The relevant variable in the data set is called `gender`. However, you will see that the names of the different gender groups are in German. Before we start analysing, we should translate them into English. To figure out what the the labels of the different genders are, we use the `levels()` function. This function applies to factors, so we first need to convert `gender` as a factor:

```{r}

data$gender <- as.factor(data$gender)

```

Now, we can look at what the levels of our factor `gender` are:

```{r}

levels(data$gender)

```

Using `recode()`, we translate ‘männlich’ to ‘men, 'weiblich' to 'women', and 'divers' to 'non-binary':

```{r}

data <- data |> 
  mutate(gender = recode(gender, 
                         "männlich" = "men", 
                         "weiblich" = "women", 
                         "divers" = "non-binary"))

levels(data$gender)

```

Now that the genders have English names, we want to determine how many men, women, and non-binary subjects participated. This is not straightforward, as the data frame contains 24 rows for each subject. So if we were to simply count the occurrences of ‘men’, ‘women’, and ‘non-binary’ in the data, we would end up with 24 times the values of the frequencies.

To determine the actual gender distribution, we need to group the data according to the subjects' unique IDs. To do this, we apply the `group_by` function to the `submission_id` variable. We then pipe `count(gender)` to this to count the genders by `submission_id`:

```{r}

gender_count <- data |> 
  group_by(submission_id) |> 
  count(gender)

```

The result is stored in a new data frame called 'gender_count'. Now we can look at the distribution using the `table()` function:

```{r}

table(gender_count$gender)

```

Alternatively, we can use the `distinct()` function to keep only unique occurrences (exactly: the first unique occurrence) of each submission_id. The argument `.keep_all` is set to `TRUE`, which means that all other variables in the data frame are kept and not deleted:

```{r}

gender_count <- data |> 
  distinct(submission_id, .keep_all = TRUE)

table(gender_count$gender)

```

The gender distribution is very uneven: 109 men, 47 women, and 3 non-binary people participated in the study.

The uneven gender distribution is likely to skew our visualisation. To solve this problem, we will, like @fricke2024semantic, use relative rather than absolute frequencies and exclude the very small group of three non-binary participants. (move this part?)

### Gender vs. emoji understanding

Next, we calculate the relative frequencies of the different levels of emoji understanding for each gender: How well do the different gender groups report to understand emojis?

variable `emoji_understanding`

Again, we have to convert `emoji_understanding` as a factor and translate its levels:

```{r}
data$emoji_understanding <- as.factor(data$emoji_understanding)
levels(data$emoji_understanding)

```

```{r}

data <- data |> 
    mutate(emoji_understanding = recode(emoji_understanding,
                                        "mittelmäßig" = "moderate",
                                        "eher gut" = "rather good",
                                        "gut" = "good",
                                        "sehr gut" = "very good"))

```

Reorder them:

```{r}

data <- data |> 
    mutate(emoji_understanding = recode(emoji_understanding,
                                        "mittelmäßig" = "moderate",
                                        "eher gut" = "rather good",
                                        "gut" = "good",
                                        "sehr gut" = "very good")) |>
    mutate(emoji_understanding = factor(emoji_understanding,
                                        levels = c("moderate",
                                                   "rather good",
                                                   "good",
                                                   "very good")))

```

To do this, we create a new data frame ‘gender_emoji_count’ and again only keep the unique submission_id. We group the data by gender and count the frequencies for the different gender groups within the emoji_understanding variable:

```{r}

gender_understanding_count <- data |>
  distinct(submission_id, .keep_all = TRUE) |> 
  group_by(gender) |> 
  count(gender, emoji_understanding)

```

Add relative frequencies:

```{r}

gender_understanding_count <- data |>
  distinct(submission_id, .keep_all = TRUE) |> 
  group_by(gender) |> 
  count(gender, emoji_understanding) |> 
  mutate(total = sum(n), 
         percentage = (n/total) * 100)

```

Print the results:

```{r}

gender_understanding_count <- gender_understanding_count |> 
  select(gender, emoji_understanding, n, percentage)

print(gender_understanding_count)

```

Formatting the table nicely using the knitr library:

```{r}

#install.packages("knitr")
#library(knitr)
#knitr::kable(gender_understanding_count, caption = "X")

```

```{r}

#install.packages("formattable")
#library(formattable)
#formattable(gender_understanding_count)

```

```{r}

#install.packages("gt")
#library(gt)
#gt(gender_understanding_count)

```

### Walkthrough bar plot

```{r}

gender_understanding_count <- gender_understanding_count |> 
  filter(gender != "divers")

```

Plot self-reported emoji understanding by gender (male and female), relative frequencies, adjust color manually to colors of @fricke2024semantic:

```{r}

ggplot(gender_understanding_count, aes(x = emoji_understanding, y = percentage, fill = gender)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Self-reported Emoji Understanding by Gender",
       x = "Emoji understanding",
       y = "Percent") #+
  #scale_fill_manual(values=c("#003560", "#B61E3E"))
```

### Emoji use

```{r match count}

# match_count <- data |> 
#   group_by(match) |> 
#   count()

#   match     n
#   <chr>  <int>
# 1 no       583
# 2 yes     1325

```

```{r plot match x emoji use}

# #trying to see whether there is a correlation of emoji use and matching accuracy
# match_use_count <- data |> 
#   group_by(match, emoji_use) |> 
#   count()
# 
# match_use_count |> 
#   group_by(emoji_use) |> 
#   ggplot(aes(x = emoji_use, y = n, fill = match)) +
#   geom_bar(stat = "identity", position = "dodge") + #better with position = "dodge" or default position = "stack"?
#   labs(x = "Use frequency", y = "count")
# #there seem to be considerable differences between values
# 
# match_use_count |> 
#   ggplot(aes(x = emoji_use, y = n, fill = match)) + 
#   geom_bar(stat = "identity", show.legend = TRUE, position = "fill") +
#   scale_fill_brewer(palette="Set1")+
#   labs(title = "Do participants that use emojis less frequently have a lower matching accuracy?",
#        x = "Use frequency",
#        y = "Ratio")+
#   coord_flip()

#the plot does not really look meaningful, i.e. there is not a real difference when scaled up to 100%

```

## AU plot

### Data preparation

Create a column with the experimental conditions (AU+, AU-, and filler/control items) using a combination of str_detect, case_when and mutate:

```{r}

#delete this code chunk?

data <- data |>
  mutate(AU_difference = case_when(str_detect(name, "AU") ~ "AU+",
                                   str_detect(name, "N") ~ "AU-",
                                   str_detect(name, "filler") ~ "filler",
                                   .default = NULL))

table(data$AU_difference)

```

Filter out filler emojis:

```{r}

data <- data |>
  filter(AU_difference != "filler")

# alternative (if code chunk above is deleted): 
#data <- data |> 
#  filter(!str_detect(name, "filler"))

```

Define contexts using a combination of str_detect, case_when and mutate (and check output with table()):

```{r}

data <- data |> 
  mutate(context = case_when(str_detect(question, "freut sich") ~ "happiness", #Fricke et al.: general happiness
                             str_detect(question, "lacht") ~ "(cheeky) laughter", #hearty laughter 

                             str_detect(question, "macht sich Sorgen") ~ "concern",
                             str_detect(question, "ist überrascht") ~ "surprise",
                             str_detect(question, "ist etwas genervt") ~ "mild irritation",
                             str_detect(question, "ärgert sich") ~ "annoyance",
                             str_detect(question, "amüsiert sich") ~ "amusement",
                             str_detect(question, "ist überglücklich") ~ "(intense) happiness", #overhappy
                             str_detect(question, "ist enttäuscht") ~ "mild disappointment",
                             #str_detect(question, "ist enttäuscht") ~ "moderate disappointment",
                             str_detect(question, "ist gut gelaunt") ~ "happiness2", #called this "happiness2" for now, Fricke et al.: happiness
                             str_detect(question, "ist verlegen") ~ "bashfulness",
                                   .default = NULL))

table(data$context)

```

Problem: emoji pair "slightly frowning face" and "frowning face" with the same question/context "ist enttäuscht". This is only resolvable using/citing the information from the original analysis script? (meaning of N-36 = "mild disappointment", meaning of N-37 = "moderate disappointment")

```{r}

data <- data |> 
  mutate(context = case_when(
                             str_detect(name, "N-36") ~ "mild disappointment",
                             str_detect(name, "N-37") ~ "moderate disappointment",
                                   .default = context))

table(data$context)

```

Define matches:

```{r}

data <- data |> 
  mutate(
  match = case_when( #called it match for now, potentially the only match column needed?
    context == "happiness" & response == "grinning_face_with_big_eyes" ~ "yes",
    context == "(cheeky) laughter" & response == "grinning_squinting_face" ~ "yes",
    context == "concern" & response == "hushed_face" ~ "yes",
    context == "surprise" & response == "astonished_face" ~ "yes",
    context == "mild irritation" & response == "neutral_face" ~ "yes",
    context == "annoyance" & response == "expressionless_face" ~ "yes",
    context == "amusement" & response == "grinning_face_with_smiling_eyes" ~ "yes",
    context == "(intense) happiness" & response == "beaming_face_with_smiling_eyes" ~ "yes",
    context == "mild disappointment" & response == "slightly_frowning_face" ~ "yes",
    context == "moderate disappointment" & response == "frowning_face" ~ "yes",
    context == "happiness2" & response == "smiling_face_with_smiling_eyes" ~ "yes",
    context == "bashfulness" & response == "smiling_face" ~ "yes",
    .default = "no"))

```

```{r AU difference , matching rates, context}

perc_AU_diff <- data |> 
  group_by(context) |> 
  count(match) |> #counts matches and non-matches (match((yes/no)) for each context
  mutate(percent = round(n/sum(n)*100, 2)) #creates a new column with the percentages for each of the above counts (in relation to the sum of all matches/non-matches within each context, rounded to 2 digits)

```

Demonstrating why we cannot simply build the plot using facet_wrap (potentially unnecessary, I was just trying stuff out)

```{r}
perc_AU_diff2 <- perc_AU_diff <- data |> 
  group_by(context, AU_difference) |> 
  count(match) |> #counts matches and non-matches (match((yes/no)) for each context
  mutate(percent = round(n/sum(n)*100, 2))
  
plot_AU_facet <- perc_AU_diff2 |> 
mutate(context = factor(context, levels = c("concern", "surprise", "happiness", "(cheeky) laughter", "mild irritation", "annoyance", "mild disappointment", "moderate disappointment", "amusement", "(intense) happiness", "happiness2", "bashfulness"))) |> 
ggplot(aes(x = percent, y = context, fill = match)) +
geom_bar(stat = "identity") +
facet_wrap(~AU_difference) +
geom_text(aes(label = percent), position = position_stack(vjust = 0.5))

plot_AU_facet
```

problem: The pairs are indiscernible, difficult to add emojis at the appropiate positions

Creating a stacked bar plot for the first (AU+) condition, emoji pair 😯 😲, contexts concern and surprise.

```{r}

plot_concern_surprise <- perc_AU_diff |> 
filter(context == "concern" | context == "surprise") |> 
ggplot(aes(x = context, y = percent, fill = match)) +
geom_bar(stat = "identity") +
scale_x_discrete(limits = c("concern", "surprise")) +
geom_text(aes(label = percent), position = position_stack(vjust = 0.5)) +
labs (x= "context", y = "percent", title = "😯 😲") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))

plot_concern_surprise

```

Since we have to do this with all emoji pairs, we define a function.

```{r}

plot_AU_matches <- function(contexts, emojis) {
  perc_AU_diff |> 
    filter(context %in% contexts) |> 
    ggplot(aes(x = context, y = percent, fill = match)) +
    geom_col() +
    scale_x_discrete(limits = contexts) +
    geom_text(aes(label = percent), position = position_stack(vjust = 0.5)) +
    labs (x= "context", y = "percent", title = emojis) +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5))
}

```

We apply this function to all emoji pairs and contexts.

```{r}

plot_concern_surprise <- plot_AU_matches(c("concern", "surprise"), "😯 😲")
plot_happiness_cheeky <- plot_AU_matches(c("happiness", "(cheeky) laughter"), "😃 😆")
plot_mild_irr_annoyance <- plot_AU_matches(c("mild irritation", "annoyance"), "😐 😑")
plot_mild_disapp_mod_dissap <- plot_AU_matches(c("mild disappointment", "moderate disappointment"), "🙁️ ☹️")
plot_amusement_int_happiness <- plot_AU_matches(c("amusement", "(intense) happiness"), "😄 😁")
plot_happiness2_bashfulness <- plot_AU_matches(c("happiness2", "bashfulness"), "😊 ☺️")

```

### Patchwork

By applying our function `plot_AU_matches` to all emoji pairs and contexts, we have created one barplot for each emoji pair. We will use the `patchwork` package (@pedersen2024patchwork) to assemble the plots in an overview. As the name suggests, the `patchwork` package enables us to patch several plots together and arrange them nicely, so that the finished graph will be cohesive and informative.

![Patchwork artwork by Allison Horst](images/patchwork.png)

In line with the research question of @fricke2024semantic, we want to compare the matching rates of emojis and contexts in the \[AU+\] condition with the matching rates in the \[AU-\] condition. In the `patchwork` package, plots are combined by `|` (horizontally), `/` (vertically), or `+` (generally).

First, let us plan the layout of our final graph with some placeholder names:

```         
p1 <- x / y / z

p2 <- a / b / c

p_combined <- p1 | p2
```

In each of the patchworks `p1` and `p2`, three plots are stacked on top of each other. These will be the plots of the \[AU+\] condition and the \[AU-\] condition. We will then put these patchworks next to each other for comparison (`p_combined`). The final graph will have two columns and three rows.

Now, we simply need to fill in the names of the plots and choose some meaningful names:

```{r}
#[AU+] condition:
AU_plus_patch <- 
  plot_concern_surprise / plot_happiness_cheeky / plot_mild_irr_annoyance

#[AU-] condition:
AU_minus_patch <- 
  plot_mild_disapp_mod_dissap / plot_amusement_int_happiness / plot_happiness2_bashfulness
```

The `plot_layout` function takes the argument `guides`. By setting this argument to `"collect"`, identical legends of all plots within the patchwork are merged.

```{r}
#AU+ condition:
AU_plus_patch <- AU_plus_patch +
  plot_layout(guides = "collect")

#AU- condition:
AU_minus_patch <- AU_minus_patch +
  plot_layout(guides = "collect")
```

Since `AU_plus_patch` and `AU_minus_patch` are to be combined in one graph, we need to add titles to them to keep them apart. Technically, it is possible (and recommended!) to use the `plot_annotation` function of the `patchwork` package for this. However, annotations of this function are only shown at the highest nesting level. As we will be building a double-nested plot, any annotations we do on the "blocks-of-three"-level will not be displayed. We can work around this by using the function `wrap_elements`. This fixates the blocks in their current state and allows us to add titles in the form of `ggtitles` which relate the blocks to the conditions. Unfortunately, there is one small downside to this approach, as we will see in a second.

```{r}
AU_plus_patch <- wrap_elements(plot = AU_plus_patch) +
  ggtitle("[AU+] condition")

AU_minus_patch <- wrap_elements(plot = AU_minus_patch) +
  ggtitle("[AU-] condition")
```

Finally, we put both elements together to get our final graph.

```{r}
AU_combined_patch1 <- AU_plus_patch | AU_minus_patch

AU_combined_patch1
```

```{r image AU plot, include=FALSE}

ggsave(filename = "images/AU_plot.png", width = 3400, height = 2000, units = "px")

```

This graph contains information on the matching rates of all emoji pairs with their contexts. However, you will probably notice that the graph contains two identical legends. This is not ideal but it is the trade-off we take by using the `wrap_elements` function: We have fixated the patchworks in their state with their legends, therefore the legends cannot be merged later. There are a couple of other options that will produce other outcomes, however, none is going to be perfect.

The options are to (1) delete the legends from both blocks, (2) keep the legend of one block and delete the other (this makes the bars take up the space of the legend, i.e. the bars in one block become wider than in the other one), or (3) keep the legends of all six plots. We have opted to create one legend for each condition, but feel free to try the other options for yourself and see how it affects the final product.

As you have now experienced, building plots and assembling them can be quite fiddly. You may get lost in details and may need to accept some trade-offs. It can take some time and a lot of trial-and-error to make the final plot look like what you have imagined. However, there is a solution for (almost) anything and hopefully, the beautiful graph you create in the process will make up for the trouble.

::: callout-tip
#### Quiz time! {.unnumbered}

[**Q1.**]{style="color:green;"} Looking at the final patchwork, which "sub-plot" shows the most significant finding?

```{r echo=FALSE, results="asis"}

check_question("lower left", options = c("upper left", "upper right", "middle left", "middle right", "lower left", "lower right"), type = "radio", 
random_answer_order = TRUE,
button_label = "Check answer", q_id = 5,
right = "That´s right! There is a notable difference between the matching rates.",
wrong = "Not quite, try again.")
```

[**Q2.**]{style="color:green;"} Which interpretation of this finding is most accurate?
:::

::: {.callout-note title="Inserting emojis in R"}
(move this chapter/subchapter?)

Insert emojis via emoji keyboard (Shortcut fn+e on Mac), also available in R Studio (Edit -\> Emojis & Symbols). This is the easiest way. Alternatively, there are emoji libraries, e.g. "emo(ji)" (<https://github.com/hadley/emo>).

As we want to display emojis within plots using ggplot: We have to use AGG/Cairo? as Backend in R Studio (Tools -\> Global Options -\> Graphics -\> Backend -\> AGG) \[explain AGG/Cairo\]. Only necessary for Mac?

For rendering the output from qmd (or Markdown?) to HTML (or pdf?) we can:

-   save the plots with ggsave() and insert them
-   use the ragg library (<https://ragg.r-lib.org>) ("ragg can be used as the graphic back-end to the RStudio device (for RStudio \>= 1.4) by choosing *AGG* as the backend in the graphics pane in general options (see screenshot)")
:::

## Conclusion

## References
